{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ee4b771",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 21:36:51.950980: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "b6688576",
   "metadata": {},
   "outputs": [],
   "source": [
    "vueltas = pd.read_csv(\"../dataset_todos_pilotos/vueltas_austria_final.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "id": "096f4b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pd/wpkltt694qx207z03w_cmlbh0000gn/T/ipykernel_85537/1494221414.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vueltas['makeStop'][0] = 0\n"
     ]
    }
   ],
   "source": [
    "vueltas['makeStop'] = vueltas['makeStop'].shift(1)   \n",
    "vueltas['makeStop'][0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "f20c1e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = [\"Stint\", \"Piloto\", 'anyo', 'makeStop']\n",
    "vueltas = vueltas[columnas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "id": "9aafbad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pd/wpkltt694qx207z03w_cmlbh0000gn/T/ipykernel_85537/2338451242.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vueltas_train.drop(['Piloto'], axis = 1, inplace = True)\n"
     ]
    }
   ],
   "source": [
    "piloto=\"alonso\"\n",
    "\n",
    "#vueltas = vueltas.drop(['Piloto'], axis = 1)\n",
    "\n",
    "#Entrenamiento con todos pilotos -> TODO\n",
    "\n",
    "vueltas_train = vueltas[vueltas['anyo'].isin([2018, 2019, 2020])]\n",
    "vueltas_validation = vueltas[vueltas['anyo'].isin([2021])]\n",
    "vueltas_test = vueltas[vueltas['anyo'] == 2022]\n",
    "\n",
    "#vueltas_train = vueltas_train[vueltas_train['Piloto'] == \"hamilton\"]\n",
    "\n",
    "#vueltas_validation = vueltas_validation[vueltas_validation['Piloto'] == \"max_verstappen\"]\n",
    "vueltas_test = vueltas_test[vueltas_test['Piloto'] == piloto]\n",
    "\n",
    "#vueltas_train = vueltas_train.drop(['anyo'], axis=1)\n",
    "vueltas_validation = vueltas_validation.drop(['anyo'], axis=1)\n",
    "\n",
    "vueltas_test = vueltas_test.drop(['anyo'], axis=1)\n",
    "vueltas_train.drop(['Piloto'], axis = 1, inplace = True)\n",
    "vueltas_test.drop(['Piloto'], axis = 1, inplace = True)\n",
    "vueltas_validation.drop(['Piloto'], axis = 1, inplace = True)\n",
    "vueltas_train = vueltas_train.drop(['Stint'], axis=1)\n",
    "vueltas_validation = vueltas_validation.drop(['Stint'], axis=1)\n",
    "vueltas_test = vueltas_test.drop(['Stint'], axis=1)\n",
    "\n",
    "vueltas_train = vueltas_train.astype('float')\n",
    "vueltas_validation = vueltas_validation.astype(float)\n",
    "vueltas_test = vueltas_test.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "id": "65166273",
   "metadata": {},
   "outputs": [],
   "source": [
    "vueltas_train_18 = vueltas_train[vueltas_train['anyo'] == 2018]\n",
    "\n",
    "vueltas_train_18 = vueltas_train_18.drop('anyo', axis=1)\n",
    "vueltas_train_18['makeStop'] = vueltas_train_18['makeStop'].astype('int32')\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(vueltas_train_18)\n",
    "vueltas_train_scaler_18= scaler.transform(vueltas_train_18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "60ffe789",
   "metadata": {},
   "outputs": [],
   "source": [
    "vueltas_train_19 = vueltas_train[vueltas_train['anyo'] == 2019]\n",
    "\n",
    "vueltas_train_19 = vueltas_train_19.drop('anyo', axis=1)\n",
    "vueltas_train_19['makeStop'] = vueltas_train_19['makeStop'].astype('int32')\n",
    "\n",
    "scaler.fit(vueltas_train_19)\n",
    "vueltas_train_scaler_19= scaler.transform(vueltas_train_19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "435d48a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vueltas_train_20 = vueltas_train[vueltas_train['anyo'] == 2020]\n",
    "\n",
    "vueltas_train_20 = vueltas_train_20.drop('anyo', axis=1)\n",
    "vueltas_train_20['makeStop'] = vueltas_train_20['makeStop'].astype('int32')\n",
    "\n",
    "scaler.fit(vueltas_train_20)\n",
    "vueltas_train_scaler_20= scaler.transform(vueltas_train_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "4b435a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vueltas_test_scaler = scaler.transform(vueltas_test)\n",
    "vueltas_validation_scaler = scaler.transform(vueltas_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "83ece4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = []\n",
    "trainY = []\n",
    "testX = []\n",
    "testY = []\n",
    "validationX = []\n",
    "validationY = []\n",
    "loopback = 8 # Esto es el numero de muestras que usara en el pasado \n",
    "future = 1 # Esto es el numero de hechos futuros que usará como salida a las 10 muestras del pasado\n",
    "\n",
    "for i in range (loopback, len(vueltas_train_scaler_18) -future +1):\n",
    "    trainX.append(vueltas_train_scaler_18[i-loopback:i, 0:vueltas_train_18.shape[1]])\n",
    "    trainY.append(vueltas_train_scaler_18[i + future - 1:i + future,5])\n",
    "    \n",
    "for i in range (loopback, len(vueltas_train_scaler_19) -future +1):\n",
    "    trainX.append(vueltas_train_scaler_19[i-loopback:i, 0:vueltas_train_19.shape[1]])\n",
    "    trainY.append(vueltas_train_scaler_19[i + future - 1:i + future,5])\n",
    "    \n",
    "for i in range (loopback, len(vueltas_train_scaler_20) -future +1):\n",
    "    trainX.append(vueltas_train_scaler_20[i-loopback:i, 0:vueltas_train_20.shape[1]])\n",
    "    trainY.append(vueltas_train_scaler_20[i + future - 1:i + future,5])\n",
    " \n",
    "for i in range (loopback, len(vueltas_test_scaler) -future +1):\n",
    "        testX.append(vueltas_test_scaler[i-loopback:i, 0:vueltas_test.shape[1]])\n",
    "        testY.append(vueltas_test_scaler[i + future - 1:i + future,5])\n",
    "        \n",
    "    \n",
    "for i in range (loopback, len(vueltas_validation_scaler) -future +1):\n",
    "    validationX.append(vueltas_validation_scaler[i-loopback:i, 0:vueltas_validation.shape[1]])\n",
    "    validationY.append(vueltas_validation_scaler[i + future - 1:i + future,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "748744b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY, testX, testY, validationX, validationY = np.array(trainX), np.array(trainY), np.array(testX), np.array(testY), np.array(validationX), np.array(validationY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16e12f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread IPythonHistorySavingThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sergio/anaconda3/lib/python3.10/site-packages/IPython/core/history.py\", line 831, in writeout_cache\n",
      "    self._writeout_input_cache(conn)\n",
      "  File \"/Users/sergio/anaconda3/lib/python3.10/site-packages/IPython/core/history.py\", line 814, in _writeout_input_cache\n",
      "    conn.execute(\"INSERT INTO history VALUES (?, ?, ?, ?)\",\n",
      "sqlite3.IntegrityError: UNIQUE constraint failed: history.session, history.line\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sergio/anaconda3/lib/python3.10/site-packages/IPython/core/history.py\", line 886, in run\n",
      "    self.history_manager.writeout_cache(self.db)\n",
      "  File \"/Users/sergio/anaconda3/lib/python3.10/site-packages/decorator.py\", line 232, in fun\n",
      "    return caller(func, *(extras + args), **kw)\n",
      "  File \"/Users/sergio/anaconda3/lib/python3.10/site-packages/IPython/core/history.py\", line 60, in only_when_enabled\n",
      "    return f(self, *a, **kw)\n",
      "  File \"/Users/sergio/anaconda3/lib/python3.10/site-packages/IPython/core/history.py\", line 834, in writeout_cache\n",
      "    print(\"ERROR! Session/line number was not unique in\",\n",
      "ValueError: I/O operation on closed file.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sergio/anaconda3/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/sergio/anaconda3/lib/python3.10/site-packages/decorator.py\", line 232, in fun\n",
      "    return caller(func, *(extras + args), **kw)\n",
      "  File \"/Users/sergio/anaconda3/lib/python3.10/site-packages/IPython/core/history.py\", line 60, in only_when_enabled\n",
      "    return f(self, *a, **kw)\n",
      "  File \"/Users/sergio/anaconda3/lib/python3.10/site-packages/IPython/core/history.py\", line 888, in run\n",
      "    print((\"The history saving thread hit an unexpected error (%s).\"\n",
      "ValueError: I/O operation on closed file.\n",
      "2023-07-27 23:32:35.831629: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-27 23:32:35.832676: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-27 23:32:35.834098: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-27 23:32:36.028863: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-27 23:32:36.030029: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-27 23:32:36.031068: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-27 23:32:36.217619: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-27 23:32:36.218697: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-27 23:32:36.220142: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(512, activation='tanh', input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256, activation='tanh', return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128, activation='tanh', return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=\"adam\", loss= \"binary_crossentropy\") \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48f6c99",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(trainX, trainY, epochs=12, batch_size=128, validation_split=0.0, verbose=1)\n",
    "plt.plot(history.history['loss'], label='Training loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10c1eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_val = model.predict(validationX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db019bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60536c0",
   "metadata": {},
   "source": [
    "### Sacamos el threeshold con los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "8e959713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El umbral óptimo según la curva ROC es: 0.12214838\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "\n",
    "# Etiquetas reales (0 o 1 según la clase verdadera)\n",
    "true_labels = validationY\n",
    "\n",
    "# Calculamos la curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(true_labels, predictions_val)\n",
    "\n",
    "# Encontramos el umbral que maximiza la suma de sensibilidad y especificidad\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "\n",
    "print(\"El umbral óptimo según la curva ROC es:\", optimal_threshold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a51e2d3",
   "metadata": {},
   "source": [
    "### Sacamos las predicciones del año 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "b6a40816",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 23:32:14.095025: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-27 23:32:14.096405: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-27 23:32:14.097593: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-27 23:32:14.275371: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-27 23:32:14.276448: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-27 23:32:14.277542: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "7f56f461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03351758,  0.20437557, -0.02111478, ..., -0.05331159,\n",
       "         0.06413545,  0.07341505],\n",
       "       [-0.03054788,  0.20104264, -0.02177547, ..., -0.05536369,\n",
       "         0.06169508,  0.07412928],\n",
       "       [-0.02752284,  0.19847758, -0.02245921, ..., -0.0574402 ,\n",
       "         0.05951459,  0.0747622 ],\n",
       "       ...,\n",
       "       [ 0.03010956,  0.2094733 ,  0.00778032, ..., -0.1103133 ,\n",
       "        -0.00023082,  0.0851691 ],\n",
       "       [ 0.02913165,  0.21131384,  0.01062854, ..., -0.107748  ,\n",
       "        -0.00391997,  0.08669841],\n",
       "       [ 0.02844639,  0.21237837,  0.0119427 , ..., -0.10617918,\n",
       "        -0.0059178 ,  0.08900773]], dtype=float32)"
      ]
     },
     "execution_count": 677,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "e9aca464",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[predictions>optimal_threshold] =1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "8bde41ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[predictions<=optimal_threshold] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "4ca27cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 680,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "1188acbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and multilabel-indicator targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[681], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[0;32m----> 3\u001b[0m metricas \u001b[38;5;241m=\u001b[39m \u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(metricas)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2310\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassification_report\u001b[39m(\n\u001b[1;32m   2196\u001b[0m     y_true,\n\u001b[1;32m   2197\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2204\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2205\u001b[0m ):\n\u001b[1;32m   2206\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m \n\u001b[1;32m   2208\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2307\u001b[0m \u001b[38;5;124;03m    <BLANKLINE>\u001b[39;00m\n\u001b[1;32m   2308\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2310\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2313\u001b[0m         labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:95\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     92\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     97\u001b[0m             type_true, type_pred\n\u001b[1;32m     98\u001b[0m         )\n\u001b[1;32m     99\u001b[0m     )\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    102\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and multilabel-indicator targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "metricas = classification_report(testY, predictions)\n",
    "print(metricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72986cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy_within_range(real_values, predicted_values, within_range=3):\n",
    "    real_values = np.ravel(real_values).astype(int)\n",
    "    predicted_values = np.ravel(predicted_values).astype(int)\n",
    "\n",
    "    stop_indexes = np.where(real_values == 1)[0]\n",
    "\n",
    "    correct_laps = []\n",
    "\n",
    "    for stop_index in stop_indexes:\n",
    "        start_index = max(0, stop_index - within_range + 1)\n",
    "        #Esto lo hago para que no se me pase de la ultima vuelta\n",
    "        end_index = min(len(predicted_values), stop_index + within_range) \n",
    "\n",
    "        if 1 in predicted_values[start_index:end_index + 1]:\n",
    "            correct_laps.append(stop_index+1)\n",
    "\n",
    "    precision = len(correct_laps) / len(stop_indexes) if len(stop_indexes) > 0 else 0\n",
    "\n",
    "    return precision, correct_laps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab0cd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Guardar la salida actual para restaurarla más tarde\n",
    "original_stdout = sys.stdout\n",
    "\n",
    "# Nombre del archivo en el que se guardarán los resultados\n",
    "nombre_archivo = f\"./resultados/austria/LSTM_BCR_ROC_TRAIN181920_VAL21/{piloto}.txt\"\n",
    "\n",
    "# Abrir el archivo en modo de escritura y redirigir la salida estándar a ese archivo\n",
    "with open(nombre_archivo, \"w\") as f:\n",
    "    sys.stdout = f\n",
    "\n",
    "    # Ahora todos los prints se guardarán en el archivo en lugar de mostrarse en la consola\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "    metricas = classification_report(testY, predictions)\n",
    "    print(metricas)\n",
    "\n",
    "    rango = 2\n",
    "    accuracy, correct_laps = calculate_accuracy_within_range(testY, predictions, within_range=rango)\n",
    "    print(f\"Exactitud dentro del rango de vueltas: {accuracy:.2f}\")\n",
    "    print(f\"Vueltas en las que se ha acertado la parada o está dentro del rango con rango seteado a {rango}: {correct_laps}\")\n",
    "\n",
    "    precision = accuracy  # En este caso, la precisión es igual a la exactitud dentro del rango\n",
    "    recall = 1.0  # Recall es 1.0, ya que solo estamos considerando las paradas reales dentro del rango\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)  # Calculamos el F1-score\n",
    "\n",
    "    print(f\"Precisión: {precision:.2f}\")\n",
    "    print(f\"F1-score: {f1_score:.2f}\")\n",
    "\n",
    "    accuracy, correct_laps = calculate_accuracy_within_range(testY, predictions, within_range=0)\n",
    "    print(f\"Exactitud sin rango de vueltas: {accuracy:.2f}\")\n",
    "\n",
    "    precision = accuracy  # En este caso, la precisión es igual a la exactitud dentro del rango\n",
    "    recall = 1.0  # Recall es 1.0, ya que solo estamos considerando las paradas reales dentro del rango\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)  # Calculamos el F1-score\n",
    "\n",
    "    print(f\"Precisión: {precision:.2f}\")\n",
    "    print(f\"F1-score: {f1_score:.2f}\")\n",
    "    \n",
    "    print(f\"El threeshold ha sido: {optimal_threshold}\")\n",
    "\n",
    "# Restaurar la salida estándar original\n",
    "sys.stdout = original_stdout\n",
    "\n",
    "print(\"Los resultados se han guardado en el archivo:\", nombre_archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a1fe95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabcce37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c96f214",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
